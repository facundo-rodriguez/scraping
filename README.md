## ğŸ¯ Objetivo

Desarrollar un script que scrapee productos de una categorÃ­a especÃ­fica del sitio https://www.extramercado.com.br, permitiendo controlar el volumen de scraping mediante parÃ¡metros personalizados:

- NÃºmero de productos a scrapear (`resultsPerPage`)
- NÃºmero de pÃ¡ginas a recorrer (`page`)

## ğŸ§ª TecnologÃ­as Utilizadas

- [Node.js](https://nodejs.org/)
- [Axios](https://www.npmjs.com/package/axios)
- [Cheerio](https://www.npmjs.com/package/cheerio)

## ğŸ“¦ Datos extraÃ­dos por producto

- ğŸ·ï¸ Nombre del producto  
- ğŸ’² Precio  
- ğŸŒ URL del producto  
- ğŸ–¼ï¸ URL de la imagen  
- ğŸ—‚ï¸ CategorÃ­a

## ğŸ› ï¸ InstalaciÃ³n y EjecuciÃ³n

### Requisitos previos

- Tener instalado [Node.js](https://nodejs.org/) y [npm](https://www.npmjs.com/)

### Pasos

```bash
git clone https://github.com/tu_usuario/tu_repositorio.git
cd tu_repositorio
npm install
node evaluation_spider.js
```

âš™ï¸ ConfiguraciÃ³n
ConfigurÃ¡ el input dentro del archivo evaluation_spider.js:

```
const scrapingInput = {
  url: 'https://www.extramercado.com.br/categoria/alimentos/doces-e-sobremesas/bomboniere',
  page: 1,              // NÃºmero de pÃ¡gina a scrapear
  resultsPerPage: 12    // Cantidad de productos por pÃ¡gina
};
```

ğŸ“¤ Salida
Por cada producto, el script imprimirÃ¡ algo como esto en consola:
```
{
  "name": "Bala Mentos 38g",
  "price": 2.99,
  "image": ["https://www.extramercado.com.br/imagem1.jpg"],
  "url": "/produto/bala-mentos-38g",
  "category": "bomboniere"
}
```
ğŸ“ Estructura del Proyecto
```
.
â”œâ”€â”€ evaluation_spider.js      # Script principal
â”œâ”€â”€ package.json              # Dependencias
â”œâ”€â”€ package-lock.json
â””â”€â”€ README.md                 # Este archivo
```

âœ… Notas adicionales:

-El sitio web carga los poductos dinamicamente, por lo que no pude usar cheerio para hacer el scarping :/. 
Buscando dentro del sitio encontre la api de donde se obtiene la informacion, y fue lo que use.

-El script utiliza una API interna del sitio para obtener los productos.

-La categorÃ­a se extrae dinÃ¡micamente a partir de la URL provista.

-Se incluye validaciÃ³n de entradas y manejo bÃ¡sico de errores.
